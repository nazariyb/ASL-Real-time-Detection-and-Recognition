{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from detection.layers.functions.prior_box import PriorBox\n",
    "from detection.data import cfg\n",
    "from detection.models.faceboxes import FaceBoxes\n",
    "from detection.utils.box_utils import decode\n",
    "from detection.utils.timer import Timer\n",
    "from detection.utils.nms.py_cpu_nms import py_cpu_nms\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.current_device()\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I',\n",
    "               'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "               'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "               'del', 'nothing', 'space']\n",
    "special_classes = {'space': ' ', 'nothing': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FaceBoxes - model for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights for FaceBoxes model which is trained on hands\n",
    "pretrained_dict = torch.load('weights/hand_boxes.pt')\n",
    "# For some reason in downloaded weights there is prefix \"module\", so get rid of them\n",
    "weights = OrderedDict((k.replace('module.', ''), v) for k, v in pretrained_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = FaceBoxes(phase='test', size=None, num_classes=2)\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "# print(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GoogLeNet - model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = models.googlenet(pretrained=True)\n",
    "num_ftrs = asl.fc.in_features\n",
    "asl.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "asl.load_state_dict(torch.load('weights/asl_recognition.pt'))\n",
    "asl.eval()\n",
    "# print(asl)\n",
    "asl = asl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_detection_trans(img):\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    return img, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_detection_trans(out, im_size, treshold = {'acc': .7, 'nms': .6}):\n",
    "    priorbox = PriorBox(cfg, out[2], im_size, phase='test')\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    loc, conf, _ = out\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    scores = conf.data.cpu().numpy()[:, 1]\n",
    "\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > treshold['acc'])[0]\n",
    "    boxes = boxes[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    order = scores.argsort()[::-1][:5000]\n",
    "    boxes = boxes[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # do NMS\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, treshold['nms'])\n",
    "    return dets[keep, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 2\n",
    "_t = {'detect': Timer(), 'misc': Timer(), 'letter_pred': Timer()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_buf = ''\n",
    "letter_buf = []\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        to_show = frame.copy()\n",
    "        img = np.float32(to_show)\n",
    "\n",
    "        if resize != 1:\n",
    "            img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        im_height, im_width, _ = img.shape\n",
    "        img, scale = pre_detection_trans(img)\n",
    "\n",
    "        _t['detect'].tic()\n",
    "        out = model(img)\n",
    "        _t['detect'].toc()\n",
    "        _t['misc'].tic()\n",
    "\n",
    "        dets = post_detection_trans(out, (im_height, im_width), {'acc': .7, 'nms': .6})\n",
    "        # keep top-K faster NMS\n",
    "        dets = dets[:750, :]\n",
    "        _t['misc'].toc()\n",
    "\n",
    "        for i in range(dets.shape[0]):\n",
    "    #         get coordinates of rectangle corners\n",
    "            min_x = max([int(dets[i][0]) - 50, 0])\n",
    "            min_y = max([int(dets[i][1]) - 50, 0])\n",
    "            max_x = min([int(dets[i][2]) + 50, frame.shape[1]])\n",
    "            max_y = min([int(dets[i][3]) + 50, frame.shape[0]])\n",
    "            cv2.rectangle(to_show, (min_x, max_y), (max_x, min_y), [0, 0, 255], 3)\n",
    "\n",
    "    #         make a prediction of letter\n",
    "            _t['letter_pred'].tic()\n",
    "            hand_img = frame[min_y:max_y, min_x:max_x]\n",
    "            hand_img = torch.stack([hand_transforms(hand_img)])\n",
    "            hand_img = hand_img.to(device)\n",
    "            asl_outputs = asl(hand_img)\n",
    "            _, preds = torch.max(asl_outputs, 1)\n",
    "            _t['letter_pred'].toc()\n",
    "\n",
    "    #         store some last predictions and choose the most frequent one\n",
    "    #         to decrease level of failures\n",
    "            letter_buf.append(class_names[preds[0]])\n",
    "            if len(letter_buf) == 10:\n",
    "                pred_letter = max(Counter(letter_buf).items(), key=lambda x: x[1])[0]\n",
    "                if pred_letter in special_classes:\n",
    "                    word_buf += special_classes[pred_letter]\n",
    "                elif pred_letter == 'del':\n",
    "                    word_buf = word_buf[:-1]\n",
    "                else:\n",
    "                    word_buf += pred_letter\n",
    "                letter_buf = []\n",
    "\n",
    "        #         clear buffer\n",
    "            if len(word_buf) > 20:\n",
    "                word_buf = word_buf[-20:]\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(to_show, word_buf,\n",
    "                    (frame.shape[0] - 30 * len(word_buf), 50),\n",
    "                    font, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('image', to_show)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for detection:  0.01618565726526005\n",
      "Average time for post processing of detector output :  0.01640164729246159\n",
      "Average time for classification:  0.0283938138573258\n"
     ]
    }
   ],
   "source": [
    "print('Average time for detection: ', _t['detect'].average_time)\n",
    "print('Average time for post processing of detector output : ', _t['misc'].average_time)\n",
    "print('Average time for classification: ', _t['letter_pred'].average_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
